{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a39140a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed64979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize MNIST CSV (0-1)\n",
    "df = pd.read_csv(\"mnist_train.csv\")\n",
    "print(\"Shape (raw):\", df.shape)\n",
    "\n",
    "# first column is label, remaining 784 columns are pixels\n",
    "label_col = df.columns[0]\n",
    "X = df.drop(columns=[label_col]).astype(np.float32)\n",
    "y = df[label_col].astype(np.int64)\n",
    "\n",
    "# Normalize to [0,1]\n",
    "X_norm = X / 255.0\n",
    "\n",
    "print(\"X_norm shape:\", X_norm.shape, \"y shape:\", y.shape)\n",
    "print(\"Min/Max after norm:\", float(X_norm.min().min()), float(X_norm.max().max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split off 20% test from the full dataset\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_norm, y, test_size=0.20, stratify=y\n",
    ")\n",
    "\n",
    "# From the remaining 80%, take 25% as validation (0.25 * 0.80 = 0.20 overall)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Shapes ->\",\n",
    "    f\"train: {X_train.shape}\",\n",
    "    f\"val: {X_val.shape}\",\n",
    "    f\"test: {X_test.shape}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d0334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def make_loader(X, y, batch_size=BATCH_SIZE, shuffle=False):\n",
    "    tensor_X = torch.tensor(X.values, dtype=torch.float32)\n",
    "    tensor_y = torch.tensor(y.values, dtype=torch.long)\n",
    "    ds = TensorDataset(tensor_X, tensor_y)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_loader = make_loader(X_train, y_train, shuffle=True)\n",
    "val_loader = make_loader(X_val, y_val)\n",
    "test_loader = make_loader(X_test, y_test)\n",
    "\n",
    "print(f\"Num train batches: {len(train_loader)}\")\n",
    "print(f\"Num val batches: {len(val_loader)}\")\n",
    "print(f\"Num test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to only labels 0 and 1\n",
    "# Reuse normalized features X_norm and labels y\n",
    "mask01 = y.isin([0, 1])\n",
    "X01 = X_norm[mask01].reset_index(drop=True)\n",
    "y01 = y[mask01].reset_index(drop=True)\n",
    "\n",
    "print(\"Shapes (0/1 only):\", X01.shape, y01.shape)\n",
    "print(\"Class counts:\\n\", y01.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split off 20% test from the full dataset\n",
    "X_temp_01, X_test_01, y_temp_01, y_test_01 = train_test_split(\n",
    "    X01, y01, test_size=0.20, stratify=y01\n",
    ")\n",
    "\n",
    "# From the remaining 80%, take 25% as validation (0.25 * 0.80 = 0.20 overall)\n",
    "X_train_01, X_val_01, y_train_01, y_val_01 = train_test_split(\n",
    "    X_temp_01, y_temp_01, test_size=0.25, stratify=y_temp_01\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Shapes ->\",\n",
    "    f\"train: {X_train_01.shape}\",\n",
    "    f\"val: {X_val_01.shape}\",\n",
    "    f\"test: {X_test_01.shape}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b67f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335823f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_BIN = 64\n",
    "\n",
    "def make_loader_bin(X_df, y_series, batch_size=BATCH_SIZE_BIN, shuffle=False):\n",
    "    X_t = torch.tensor(X_df.values, dtype=torch.float32)\n",
    "    y_t = torch.tensor(y_series.values, dtype=torch.float32).view(-1, 1)  # (N,1)\n",
    "    ds = TensorDataset(X_t, y_t)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_01_loader_bin = make_loader_bin(X_train_01, y_train_01, shuffle=True)\n",
    "val_01_loader_bin = make_loader_bin(X_val_01, y_val_01)\n",
    "test_01_loader_bin = make_loader_bin(X_test_01, y_test_01)\n",
    "\n",
    "len(train_01_loader_bin), len(val_01_loader_bin), len(test_01_loader_bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch forward functions: logit and probability\n",
    "\n",
    "def logit_torch(X: torch.Tensor, W: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    return X @ W + b  # (N,1)\n",
    "\n",
    "def predict_proba(X: torch.Tensor, W: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.sigmoid(logit_torch(X, W, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d68093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters W and b (requires_grad=True)\n",
    "INPUT_DIM = X_train_01.shape[1]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "W = torch.rand((INPUT_DIM, 1), dtype=torch.float32, requires_grad=True, device=device)\n",
    "b = torch.rand((1,), dtype=torch.float32, requires_grad=True, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross-entropy loss (PyTorch tensors) and manual GD training (lr=0.01)\n",
    "\n",
    "\n",
    "EPS = 1e-7\n",
    "\n",
    "def bce_loss(probs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    probs = torch.clamp(probs, EPS, 1.0 - EPS)\n",
    "    return -(targets * torch.log(probs) + (1.0 - targets) * torch.log(1.0 - probs)).mean()\n",
    "\n",
    "LR = 0.01\n",
    "MAX_EPOCHS = 100\n",
    "PATIENCE = 5\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "patience_left = PATIENCE\n",
    "history = {\"epoch\": [], \"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for epoch in range(1, MAX_EPOCHS + 1):\n",
    "    # Train\n",
    "    W.grad = None\n",
    "    b.grad = None\n",
    "    model_train_loss_sum = 0.0\n",
    "    train_correct = 0\n",
    "    num_train_samples = 0\n",
    "\n",
    "    for xb, yb in train_01_loader_bin:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        logits = logit_torch(xb, W, b)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        loss = bce_loss(probs, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            W -= LR * W.grad\n",
    "            b -= LR * b.grad\n",
    "            W.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "\n",
    "        preds = (probs >= 0.5).float()\n",
    "        train_correct += (preds == yb).sum().item()\n",
    "\n",
    "        model_train_loss_sum += loss.item() * xb.size(0)\n",
    "        num_train_samples += xb.size(0)\n",
    "\n",
    "    train_loss = model_train_loss_sum / max(1, num_train_samples)\n",
    "    train_acc = train_correct / max(1, num_train_samples)\n",
    "\n",
    "    # Validation\n",
    "    val_loss_sum = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_01_loader_bin:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = logit_torch(xb, W, b)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            loss = bce_loss(probs, yb)\n",
    "            val_loss_sum += loss.item() * xb.size(0)\n",
    "\n",
    "            preds = (probs >= 0.5).float()\n",
    "            val_correct += (preds == yb).sum().item()\n",
    "            val_total += yb.numel()\n",
    "\n",
    "    val_loss = val_loss_sum / max(1, val_total)\n",
    "    val_acc = val_correct / max(1, val_total)\n",
    "\n",
    "    history[\"epoch\"].append(epoch)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | train_acc={train_acc:.4f} | val_acc={val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping on val_loss\n",
    "    if val_loss + 1e-5 < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_left = PATIENCE\n",
    "    else:\n",
    "        patience_left -= 1\n",
    "        if patience_left == 0:\n",
    "            print(\"Early stopping: no improvement in validation loss.\")\n",
    "            break\n",
    "\n",
    "history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6666e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training/validation loss and accuracy curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = history[\"epoch\"]\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curves\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b0cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test accuracy and confusion matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "model_test_correct = 0\n",
    "model_test_total = 0\n",
    "all_true = []\n",
    "all_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_01_loader_bin:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        probs = torch.sigmoid(logit_torch(xb, W, b))\n",
    "        preds = (probs >= 0.5).float()\n",
    "        model_test_correct += (preds == yb).sum().item()\n",
    "        model_test_total += yb.numel()\n",
    "\n",
    "        all_true.append(yb.cpu())\n",
    "        all_pred.append(preds.cpu())\n",
    "\n",
    "y_true = torch.vstack(all_true).numpy().ravel()\n",
    "y_pred = torch.vstack(all_pred).numpy().ravel()\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(\"Confusion Matrix (rows: true, cols: pred):\\n\", cm)\n",
    "acc, cm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
